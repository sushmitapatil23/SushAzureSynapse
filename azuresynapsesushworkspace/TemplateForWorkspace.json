{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "azuresynapsesushworkspace"
		},
		"AzureDataLakeStorage_synapse_accountKey": {
			"type": "secureString",
			"metadata": "Secure string for 'accountKey' of 'AzureDataLakeStorage_synapse'"
		},
		"AzureDataLakeStorage_synapse_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://azuresynapsesushadlsgen2.dfs.core.windows.net/"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/Pipeline')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Wait1",
						"type": "Wait",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"waitTimeInSeconds": 1
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Pipeline_ReadNotebook')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Notebook_ReadByPipeline",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "Notebook_ReadByPipeline",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool1",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": null,
								"spark.dynamicAllocation.minExecutors": null,
								"spark.dynamicAllocation.maxExecutors": null
							},
							"driverSize": "Small",
							"numExecutors": null
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"name": {
						"type": "string",
						"defaultValue": "Pandit"
					}
				},
				"annotations": [],
				"lastPublishTime": "2025-03-21T07:02:18Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/Notebook_ReadByPipeline')]",
				"[concat(variables('workspaceId'), '/bigDataPools/sparkpool1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/RunNoteBook')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Notebook1",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "Notebookwritecsvparquet",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool1",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": null,
								"spark.dynamicAllocation.minExecutors": null,
								"spark.dynamicAllocation.maxExecutors": null
							},
							"driverSize": "Small",
							"numExecutors": null
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2025-03-18T19:22:23Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/Notebookwritecsvparquet')]",
				"[concat(variables('workspaceId'), '/bigDataPools/sparkpool1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/externaltablesqlscript')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "IF NOT EXISTS (SELECT * FROM sys.external_file_formats WHERE name = 'SynapseDelimitedTextFormat') \n\tCREATE EXTERNAL FILE FORMAT [SynapseDelimitedTextFormat] \n\tWITH ( FORMAT_TYPE = DELIMITEDTEXT ,\n\t       FORMAT_OPTIONS (\n\t\t\t FIELD_TERMINATOR = ',',\n\t\t\t USE_TYPE_DEFAULT = FALSE\n\t\t\t))\nGO\n\nIF NOT EXISTS (SELECT * FROM sys.external_data_sources WHERE name = 'azuresynapsesushcontainer_azuresynapsesushadlsgen2_dfs_core_windows_net') \n\tCREATE EXTERNAL DATA SOURCE [azuresynapsesushcontainer_azuresynapsesushadlsgen2_dfs_core_windows_net] \n\tWITH (\n\t\tLOCATION = 'abfss://azuresynapsesushcontainer@azuresynapsesushadlsgen2.dfs.core.windows.net' \n\t)\nGO\n\nCREATE EXTERNAL TABLE [dbo].[EmployeeSalary] (\n\t[C1] nvarchar(4000),\n\t[C2] nvarchar(4000),\n\t[C3] nvarchar(4000),\n\t[C4] nvarchar(4000),\n\t[C5] nvarchar(4000)\n\t)\n\tWITH (\n\tLOCATION = 'synapsedemo/EmployeeSalary.txt',\n\tDATA_SOURCE = [azuresynapsesushcontainer_azuresynapsesushadlsgen2_dfs_core_windows_net],\n\tFILE_FORMAT = [SynapseDelimitedTextFormat]\n\t)\nGO\n\n\nSELECT TOP 100 * FROM [dbo].[EmployeeSalary]\nGO",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_AutoExternalTablewithParquetFile')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "IF NOT EXISTS (SELECT * FROM sys.external_file_formats WHERE name = 'SynapseParquetFormat') \n\tCREATE EXTERNAL FILE FORMAT [SynapseParquetFormat] \n\tWITH ( FORMAT_TYPE = PARQUET)\nGO\n\nIF NOT EXISTS (SELECT * FROM sys.external_data_sources WHERE name = 'azuresynapsesushcontainer_azuresynapsesushadlsgen2_dfs_core_windows_net') \n\tCREATE EXTERNAL DATA SOURCE [azuresynapsesushcontainer_azuresynapsesushadlsgen2_dfs_core_windows_net] \n\tWITH (\n\t\tLOCATION = 'abfss://azuresynapsesushcontainer@azuresynapsesushadlsgen2.dfs.core.windows.net' \n\t)\nGO\n\nCREATE EXTERNAL TABLE dbo.AutoExternalTablewithParquetFile (\n\t[DateID] int,\n\t[MedallionID] int,\n\t[HackneyLicenseID] int,\n\t[PickupTimeID] int,\n\t[DropoffTimeID] int,\n\t[PickupGeographyID] int,\n\t[DropoffGeographyID] int,\n\t[PickupLatitude] float,\n\t[PickupLongitude] float,\n\t[PickupLatLong] nvarchar(4000),\n\t[DropoffLatitude] float,\n\t[DropoffLongitude] float,\n\t[DropoffLatLong] nvarchar(4000),\n\t[PassengerCount] int,\n\t[TripDurationSeconds] int,\n\t[TripDistanceMiles] float,\n\t[PaymentType] nvarchar(4000),\n\t[FareAmount] numeric(19,4),\n\t[SurchargeAmount] numeric(19,4),\n\t[TaxAmount] numeric(19,4),\n\t[TipAmount] numeric(19,4),\n\t[TollsAmount] numeric(19,4),\n\t[TotalAmount] numeric(19,4)\n\t)\n\tWITH (\n\tLOCATION = 'synapsedemo/NYCTripSmall.parquet',\n\tDATA_SOURCE = [azuresynapsesushcontainer_azuresynapsesushadlsgen2_dfs_core_windows_net],\n\tFILE_FORMAT = [SynapseParquetFormat]\n\t)\nGO\n\n\nSELECT TOP 100 * FROM dbo.AutoExternalTablewithParquetFile\nGO",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_CETAS')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE EXTERNAL TABLE nyctaxi.CETASpassengercountstates \nWITH\n(\n    LOCATION= 'Synapsesqldatabase/NYCTaxi/Aggdata/',\n     DATA_SOURCE= demoDataSource,\n   -- DATA_SOURCE = azuresynapsesushcontainer_azuresynapsesushadlsgen2_dfs_core_windows_net,\n    FILE_FORMAT= ParquestfileFormat\n)\nAS\nSELECT PassengerCount as PassengerCount,\n      SUM(TripDistanceMiles) as SumTripDistance_miles,\n      AVG(TripDistanceMiles) as AvgTripDistance_miles\nFROM\nOPENROWSET(\n        BULK 'https://azuresynapsesushadlsgen2.dfs.core.windows.net/azuresynapsesushcontainer/synapsedemo/NYCTripSmall.parquet',\n        FORMAT = 'PARQUET'\n    ) AS [rows]\n\nWHERE TripDistanceMiles > 0 AND PassengerCount > 0\nGROUP BY PassengerCount;\t\n\nGO\n\n--  select * from nyctaxi.CETASpassengercountstates ",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_CTAS_EmployeeHash')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE TABLE [dbo].[Employees]\n(\n    empid int NOT NULL,\n    empname NVARCHAR(50),\n    gender NVARCHAR(10)\n)\nWITH\n(\n    DISTRIBUTION = HASH (empid),\n    CLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n-- insert into Employees values (1, 'Maheer', 'Male')\n-- insert into Employees values (1, 'Ashi', 'Female')\n-- insert into Employees values (1, 'Wafa', 'Male')\n\n-- select * from [dbo].[Employees]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_CTAS_EmployeeRoundRobin')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE TABLE EmployeesNewExistingCTASEmployee\nWITH (\n    DISTRIBUTION = ROUND_ROBIN,\n    CLUSTERED COLUMNSTORE INDEX\n)\nAS\nSELECT * FROM Employees;\n\nGO\n\n-- SELECT * from EmployeesNewExistingCTASEmployee\n\n-- SELECT * INTO EmployeesNewExistingCTASEmployee2\n-- from EmployeesNewExistingCTASEmployee\n\n-- SELECT * from EmployeesNewExistingCTASEmployee2\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_EmployeeSalary')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "select \n    depname ,  SUM(salary) as totalsalary\nFROM\nOPENROWSET (\nBulk 'https://azuresynapsesushadlsgen2.dfs.core.windows.net/azuresynapsesushcontainer/synapsedemo/EmployeeSalary.txt',\nFormat= 'csv',\nHEADER_ROW = TRUE,\nPARSER_VERSION = '2.0'\n) as [RESULT]\nGROUP BY depname\n\n\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_ExternalFileFormat')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE EXTERNAL FILE FORMAT ParquetfileFormat\nWITH\n(\n    FORMAT_TYPE = PARQUET,\n    DATA_COMPRESSION = 'org.apache.hadoop.io.compress.SnappyCodec'\n)\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_ExternalTableDedicatedPool')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE EXTERNAL TABLE dbo.Dedicated_NYCTaxiTripSmall\n    (\n    DateID \tInt,\n    MedallionID Int\t,\n    HackneyLicenseID Int,\n    PickupTimeID\tInt,\n    DropoffTimeID\tInt,\n    PickupGeographyID\tInt,\n    DropoffGeographyID Int\t,\n    PickupLatitude float\t,\n    PickupLongitude float\t,\n    PickupLatLong nvarchar(4000),\n    DropoffLatitude\t float,\n    DropoffLongitude float\t,\n    DropoffLatLong nvarchar(4000)\t,\n    PassengerCount int\t,\n    TripDurationSeconds int\t,\n    TripDistanceMiles float\t,\n    PaymentType nvarchar(4000)\t,\n    FareAmount numeric(19,4)\t,\n    SurchargeAmount numeric(19,4)\t,\n    TaxAmount numeric(19,4)\t,\n    TipAmount numeric(19,4)\t,\n    TollsAmount\tnumeric(19,4),\n    TotalAmount\tnumeric(19,4)\n    )\nWITH\n    (\n        LOCATION = '/synapsedemo/NYCTripSmall.parquet',\n        DATA_SOURCE = sushadlsgen2,\n        FILE_FORMAT = SynapseParquetfileFormat     \n    )\nGO\n\n\n--  select top 10 * from dbo.Dedicated_NYCTaxiTripSmall\n\n-- Based on External table - you can copy data to Physical Table",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_NYCTaxiSmallTrip')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "IF NOT EXISTS (SELECT * FROM sys.objects O JOIN sys.schemas S ON O.schema_id = S.schema_id WHERE O.NAME = 'NYCTaxiTripSmall' AND O.TYPE = 'U' AND S.NAME = 'dbo')\nCREATE TABLE dbo.NYCTaxiTripSmall\n    (\n    DateID \tInt,\n    MedallionID Int\t,\n    HackneyLicenseID Int,\n    PickupTimeID\tInt,\n    DropoffTimeID\tInt,\n    PickupGeographyID\tInt,\n    DropoffGeographyID Int\t,\n    PickupLatitude float\t,\n    PickupLongitude float\t,\n    PickupLatLong nvarchar(4000),\n    DropoffLatitude\t float,\n    DropoffLongitude float\t,\n    DropoffLatLong nvarchar(4000)\t,\n    PassengerCount int\t,\n    TripDurationSeconds int\t,\n    TripDistanceMiles float\t,\n    PaymentType nvarchar(4000)\t,\n    FareAmount numeric(19,4)\t,\n    SurchargeAmount numeric(19,4)\t,\n    TaxAmount numeric(19,4)\t,\n    TipAmount numeric(19,4)\t,\n    TollsAmount\tnumeric(19,4),\n    TotalAmount\tnumeric(19,4)\n    )\nWITH\n    (\n    DISTRIBUTION = ROUND_ROBIN,\n     CLUSTERED COLUMNSTORE INDEX\n     -- HEAP\n    )\nGO\n\nCOPY INTO dbo.NYCTaxiTripSmall\n(DateID 1,MedallionID 2,HackneyLicenseID 3,PickupTimeID 4,DropoffTimeID 5,\nPickupGeographyID 6,DropoffGeographyID 7,PickupLatitude 8,PickupLongitude 9,\nPickupLatLong 10,DropoffLatitude 11, DropoffLongitude 12,DropoffLatLong 13,PassengerCount 14,\nTripDurationSeconds 15,TripDistanceMiles 16,PaymentType 17,FareAmount 18,SurchargeAmount 19,\nTaxAmount 20,TipAmount 21,TollsAmount 22,TotalAmount 23\n )\nFROM 'https://azuresynapsesushadlsgen2.dfs.core.windows.net/azuresynapsesushcontainer/synapsedemo/NYCTripSmall.parquet'\nWITH\n(\n    FILE_TYPE = 'PARQUET'\n    ,MAXERRORS = 0\n    ,IDENTITY_INSERT = 'OFF'\n    ,AUTO_CREATE_TABLE ='ON'\n   )\n\n--  drop TABLE dbo.NYCTaxiTripSmall\n\n--  select count(*) from dbo.NYCTaxiTripSmall\n\n/* SELECT PassengerCount as PassengerCount,\n      SUM(TripDistanceMiles) as SumTripDistance_miles,\n      AVG(TripDistanceMiles) as AvgTripDistance_miles\nINTO dbo.PassengerCountStats\nFROM  dbo.NYCTaxiTripSmall\nWHERE TripDistanceMiles > 0 AND PassengerCount > 0\nGROUP BY PassengerCount;\n\nSELECT * FROM dbo.PassengerCountStats\nORDER BY PassengerCount;  */\n ",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_PersonHash')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE TABLE [dbo].[Person]\n(\n    id int NOT NULL,\n    name nvarchar(50)\n)\nWITH\n(\n    DISTRIBUTION = HASH (id),\n    CLUSTERED COLUMNSTORE INDEX\n)\nGO\n\n-- Drop table [dbo].[Table]\n\ninsert into [dbo].[Person] values (1,'Susmita')\ninsert into [dbo].[Person] values (2,'Pandit')\n\nselect * from Person\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_externalNYCTaxiSmall')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE EXTERNAL DATA SOURCE [MyExternalDataSource]\nWITH (\n    TYPE = HADOOP,\n    LOCATION = 'https://azuresynapsesushadlsgen2.dfs.core.windows.net/azuresynapsesushcontainer/synapsedemo/NYCTripSmall.parquet'\n);\n\nCREATE EXTERNAL TABLE dbo.YourParquetTable\nWITH (\n    LOCATION = 'https://azuresynapsesushadlsgen2.dfs.core.windows.net/azuresynapsesushcontainer/synapsedemo/NYCTripSmall.parquet',\n    DATA_SOURCE = MyExternalDataSource,\n    FILE_FORMAT = ParquetFormat\n)\nAS SELECT * FROM OPENROWSET(\n    BULK 'https://azuresynapsesushadlsgen2.dfs.core.windows.net/azuresynapsesushcontainer/synapsedemo/NYCTripSmall.parquet',\n    DATA_SOURCE = 'MyExternalDataSource',\n    FORMAT='PARQUET'\n);\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_generateExternalResources')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "use synapsesqldatabase\nGO\n\n--  create master key that will protect to credentials\nCREATE MASTER KEY ENCRYPTION BY PASSWORD = 'Welcome$1Hello@1'\n\n-- go to synapse resource group and ADLS storage account -- shared access signature -- click on all checkboxes\n-- service, container , object in allowed resource types \n-- click on Generate SAS and connection string button then copy SAS Token \n-- paste it in Secret as per shown below\nCREATE DATABASE SCOPED CREDENTIAL democredential\nWITH IDENTITY = 'SHARED ACCESS SIGNATURE',\n-- SECRET = 'sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2025-03-19T15:19:58Z&st=2025-03-19T07:19:58Z&spr=https&sig=GhfgxsNwbTrzwvf8wnmlPg1MX%2FARNsEYJKQCJ5M6I3Y%3D'\nSECRET = 'sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2025-03-19T19:57:07Z&st=2025-03-19T11:57:07Z&spr=https&sig=5jdwiN6%2FshQUecoy36zCEITHc9KytYweC9ouATUCoi4%3D'\nGO\n\n-- go to synapse resource group and ADLS storage account \n-- settings  -- Endpoints -- Data Lake Storage -- Primary End Point -- Copy and paste it as per below\n\n    CREATE EXTERNAL DATA SOURCE demoDataSource WITH (\n    LOCATION = 'https://azuresynapsesushadlsgen2.dfs.core.windows.net/' ,\n    CREDENTIAL = democredential\n\n\n)\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_generateExternalResourcesDedicatedPool')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE MASTER KEY ENCRYPTION BY PASSWORD = 'Welcome$1Hello@1'\n\n-- DROP database SCOPED CREDENTIAL MSI_sushadlsgen2\n\nCREATE DATABASE SCOPED CREDENTIAL MSI_sushadlsgen2\nWITH IDENTITY = 'Managed Identity'\n\n-- go to synapse resource group and ADLS storage account \n-- settings  -- Endpoints -- Data Lake Storage -- Primary End Point -- Copy and paste it as per below\n\n    CREATE EXTERNAL DATA SOURCE sushadlsgen2 \n    WITH \n    (\n        --LOCATION = 'https://azuresynapsesushadlsgen2.dfs.core.windows.net/' ,  -- https -- not supported\n        --\n        LOCATION = 'abfss://azuresynapsesushcontainer@azuresynapsesushadlsgen2.dfs.core.windows.net',\n        CREDENTIAL = MSI_sushadlsgen2,\n        TYPE = HADOOP\n    )\n\n-- DROP external Data Source sushadlsgen2\n\n\n\nCREATE EXTERNAL FILE FORMAT SynapseParquetfileFormat\nWITH\n(\n    FORMAT_TYPE = PARQUET,\n    DATA_COMPRESSION = 'org.apache.hadoop.io.compress.SnappyCodec'\n)\n\n-- DROP external File format SynapseParquetfileFormat\n\n\nGO\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_readParquetCSVFile')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "--- Read Parquet File\n\nselect top 10 *\nfrom openrowset(\n    bulk 'https://azuresynapsesushadlsgen2.dfs.core.windows.net/azuresynapsesushcontainer/synapsedemo/NYCTripSmall.parquet',\n    format = 'parquet') as rows\n\n--- Read CSV File with limited column\n\n    select Top 10 *\n    from openrowset(\n    bulk 'https://azuresynapsesushadlsgen2.dfs.core.windows.net/azuresynapsesushcontainer/synapsedemo/Employees.csv',\n    format = 'csv',\n    PARSER_VERSION = '2.0',\n    HEADER_ROW = True\n    )\n    WITH\n    (\n        Emp_Id int, Dept_Id int, Salary int\n    )\n    as rows\n\n\n--- Read CSV File\n\n    select Top 10 *\n    from openrowset(\n    bulk 'https://azuresynapsesushadlsgen2.dfs.core.windows.net/azuresynapsesushcontainer/synapsedemo/Employees.csv',\n    format = 'csv',\n    PARSER_VERSION = '2.0',\n    HEADER_ROW = True\n    )    as rows\n\n\n    --- Read CSV File from Blob Storage \n    select Top 10 *\n    from openrowset(\n    bulk 'https://storageaccountadfsush.blob.core.windows.net/source/customerPurchases.csv',\n    format = 'csv',\n    PARSER_VERSION = '2.0',\n    HEADER_ROW = True\n    )    as rows\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_readParquetFileautoscript')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "-- This is auto-generated code\nSELECT\n    TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://azuresynapsesushadlsgen2.dfs.core.windows.net/azuresynapsesushcontainer/NYCTaxi/parquetfile/part-00000-ca9112b6-e14f-4e41-a0aa-5b4c3e7ec526-c000.snappy.parquet',\n        FORMAT = 'PARQUET'\n    ) AS [result]\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_runfromdedicatedsqlpool')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT TOP (100) [DateID]\n,[MedallionID]\n,[HackneyLicenseID]\n,[PickupTimeID]\n,[DropoffTimeID]\n,[PickupGeographyID]\n,[DropoffGeographyID]\n,[PickupLatitude]\n,[PickupLongitude]\n,[PickupLatLong]\n,[DropoffLatitude]\n,[DropoffLongitude]\n,[DropoffLatLong]\n,[PassengerCount]\n,[TripDurationSeconds]\n,[TripDistanceMiles]\n,[PaymentType]\n,[FareAmount]\n,[SurchargeAmount]\n,[TaxAmount]\n,[TipAmount]\n,[TollsAmount]\n,[TotalAmount]\n FROM [dbo].[NYCTaxiTripSmall]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_tablePassengerCountStats')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT PassengerCount as PassengerCount,\n      SUM(TripDistanceMiles) as SumTripDistance_miles,\n      AVG(TripDistanceMiles) as AvgTripDistance_miles\nINTO dbo.PassengerCountStats\nFROM  dbo.NYCTaxiTripSmall\nWHERE TripDistanceMiles > 0 AND PassengerCount > 0\nGROUP BY PassengerCount;\n\nSELECT * FROM dbo.PassengerCountStats\nORDER BY PassengerCount;\n\n-- drop table dbo.PassengerCountStats",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sql_top100PassengerCount')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT TOP (100) [PassengerCount]\n,[SumTripDistance_miles]\n,[AvgTripDistance_miles]\n FROM [nyctaxi].[dbo].[passengercountstats]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/NotebookNYCTripSmall')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "26640fda-50da-4b7d-9a19-58ef15db1a17"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\n",
							"df = spark.read.load(path = 'abfss://azuresynapsesushcontainer@azuresynapsesushadlsgen2.dfs.core.windows.net/synapsedemo/NYCTripSmall.parquet' , format = 'parquet')\n",
							"display(df.limit(10))\n",
							"df.printSchema()\n",
							"\n",
							""
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"spark.sql(\"create database if not exists nyctaxi\")\n",
							"df.write.mode(\"overwrite\").saveAsTable(\"nyctaxi.trip\")\n",
							"\n",
							"spark.sql(\"select * from nyctaxi.trip\")\n",
							"display(df)"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/NotebookNYCtaxiFetchdata')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "2e9aa532-f4d7-4a96-93ae-2936228e720c"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"df = spark.sql(\"\"\" SELECT PassengerCount as PassengerCount,\n",
							"      SUM(TripDistanceMiles) as SumTripDistance_miles,\n",
							"      AVG(TripDistanceMiles) as AvgTripDistance_miles\n",
							"FROM  nyctaxi.trip\n",
							"WHERE TripDistanceMiles > 0 AND PassengerCount > 0\n",
							"GROUP BY PassengerCount\n",
							"ORDER BY PassengerCount \"\"\" )\n",
							"display(df)\n",
							"df.write.saveAsTable(\"nyctaxi.PassengerCountStats\")"
						],
						"outputs": [],
						"execution_count": 12
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/NotebookNewparquetfile')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "6dde3dfd-cfc7-454f-acf1-70be0f0d7e9a"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://azuresynapsesushcontainer@azuresynapsesushadlsgen2.dfs.core.windows.net/NYCTaxi/parquetfile/part-00000-ca9112b6-e14f-4e41-a0aa-5b4c3e7ec526-c000.snappy.parquet', format='parquet')\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 16
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/NotebookReadDataFromAnotherLanguge')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "d0d2ec97-be7d-4782-8e90-cdfecc2f123d"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "scala"
							}
						},
						"source": [
							"%%spark\n",
							"val scala_df = spark.read.sqlanalytics(\"dedicatedsushsqlpool.dbo.person\")\n",
							"scala_df.createOrReplaceTempView(\"PersonTempTable\")"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\n",
							"python_df= spark.sql(\"select * from PersonTempTable\")\n",
							"display(python_df)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "sparksql"
							},
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"%%sql\n",
							"select * from PersonTempTable"
						],
						"outputs": [],
						"execution_count": 24
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/NotebookReadFSSPEC')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "6555f6e6-2e6a-4997-9e9f-dc2079161959"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"import fsspec\n",
							"import pandas\n",
							"\n",
							"adls_account_name = 'azuresynapsesushadlsgen2'\n",
							"adls_account_key = 'kSfTLRaUy6CSNVEyDeViq0STEzBKJ1HEFRLDRNwnUSHgahT1zi7lSbpe+eygxmfWJOKsctqk1i0h+AStR0qNjg=='\n",
							"\n",
							"fsspec_object = fsspec.open('abfss://azuresynapsesushcontainer/synapsedemo/EMP_WriteFSSPEC.csv',account_name = adls_account_name,account_key= adls_account_key)\n",
							"\n",
							"with fsspec_object.open() as f:\n",
							"    df=pandas.read_csv(f)\n",
							"\n",
							"    display(df)\n",
							""
						],
						"outputs": [],
						"execution_count": 18
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/NotebookReadWriteByPandas')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "2f0c70bb-8249-4ba7-8c6f-7771a441e89a"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"import pandas\n",
							"df = pandas.read_csv('abfss://azuresynapsesushcontainer@azuresynapsesushadlsgen2.dfs.core.windows.net/synapsedemo/EmployeeSalary.txt',\n",
							"storage_options= {'account_key' : 'kSfTLRaUy6CSNVEyDeViq0STEzBKJ1HEFRLDRNwnUSHgahT1zi7lSbpe+eygxmfWJOKsctqk1i0h+AStR0qNjg==' })\n",
							"\n",
							"display(df)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pandas\n",
							"df1 = pandas.DataFrame ({'id':[1,2], 'name':['Maheer','Wafa']})\n",
							"df1.to_csv('abfss://azuresynapsesushcontainer@azuresynapsesushadlsgen2.dfs.core.windows.net/synapsedemo/EMP_WritePandas.csv',\n",
							"storage_options= {'account_key' : 'kSfTLRaUy6CSNVEyDeViq0STEzBKJ1HEFRLDRNwnUSHgahT1zi7lSbpe+eygxmfWJOKsctqk1i0h+AStR0qNjg==' })\n",
							"\n",
							""
						],
						"outputs": [],
						"execution_count": 11
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/NotebookWriteCSV')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "3b61eec3-5b5e-4991-b5c9-32ba0671c38e"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"new_rows= [('Maheer','Male',5000),('Wafa','Male',3000)]\n",
							"demo_df= spark.createDataFrame(new_rows,['Name','Gender','Salary'])\n",
							"demo_df.show()\n",
							"demo_df.write.csv('abfss://azuresynapsesushcontainer@azuresynapsesushadlsgen2.dfs.core.windows.net/synapsedemo1/', mode='overwrite')\n",
							"demo_df.createOrReplaceTempView(\"DemoTempTable\")"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"run_control": {
								"frozen": true
							},
							"editable": false
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "sparksql"
							},
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"%%sql\n",
							"select * from DemoTempTable"
						],
						"outputs": [],
						"execution_count": 6
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/NotebookWriteFSSPEC')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "81d0b718-7c69-48d5-8566-8e6c9bcc20f0"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"import fsspec\n",
							"import pandas\n",
							"\n",
							"adls_account_name = 'azuresynapsesushadlsgen2'\n",
							"adls_account_key = 'kSfTLRaUy6CSNVEyDeViq0STEzBKJ1HEFRLDRNwnUSHgahT1zi7lSbpe+eygxmfWJOKsctqk1i0h+AStR0qNjg=='\n",
							"\n",
							"data = pandas.DataFrame({'id':[1,2,3,4], 'name':['Maheer','Wafa','sush','pandit']})\n",
							"\n",
							"fsspec_object = fsspec.open('abfss://azuresynapsesushcontainer/synapsedemo/EMP_WriteFSSPEC.csv',account_name = adls_account_name,account_key= adls_account_key, mode= 'wt')\n",
							"\n",
							"with fsspec_object.open() as f:\n",
							"    data.to_csv(f)\n",
							""
						],
						"outputs": [],
						"execution_count": 16
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_1')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "fb9db3fa-6554-4f58-8b16-82a21e623604"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"tags": [
								"parameters"
							]
						},
						"source": [
							"firstname = \"Susmita \"\n",
							"lastname = \"Pandit\"\n",
							""
						],
						"outputs": [],
						"execution_count": 41
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"print(\"Hello \" + firstname + \" \"+ lastname )"
						],
						"outputs": [],
						"execution_count": 43
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_CallReadNotebook1')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "46de8c38-d68b-41d2-a338-85c21ca528c5"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"%run /Notebook_1"
						],
						"outputs": [],
						"execution_count": 29
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_CallReadNotebook1ByParameter')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "629c2385-2431-45f0-9009-75a1e54c4032"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"tags": []
						},
						"source": [
							"%run /Notebook_1 {'firstname':'Devansh','lastname':'Patil'}"
						],
						"outputs": [],
						"execution_count": 46
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_MSSparkUtils')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "392d7c6a-d2b9-403f-a358-a95269f99dda"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"from notebookutils import mssparkutils\n",
							"mssparkutils.fs.help()\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"mssparkutils.fs.ls('/synapsedemo')"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_MSSparkUtils_Callrun_ENV')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "35f2c8cd-f82c-4f06-9f64-a0c481c1ee56"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/74978c73-22ed-4fd5-9de2-85878197ac55/resourceGroups/AzureSynapseSushRG/providers/Microsoft.Synapse/workspaces/azuresynapsesushworkspace/bigDataPools/sparkpool1",
						"name": "sparkpool1",
						"type": "Spark",
						"endpoint": "https://azuresynapsesushworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"from notebookutils import mssparkutils\n",
							"mssparkutils.notebook.run('/Notebook_MSSparkUtils_run', 90,{'firstName':'Pradeep' ,'lastname':'Patil'})"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"mssparkutils.env.help()\n",
							""
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"mssparkutils.env.getUserName()"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"mssparkutils.env.getUserId()"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"mssparkutils.env.getJobId()"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"mssparkutils.env.getWorkspaceName()"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"mssparkutils.env.getPoolName()"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"mssparkutils.env.getClusterId()"
						],
						"outputs": [],
						"execution_count": 13
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_MSSparkUtils_Exit')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "fa11080f-237d-45f7-9118-aa2f1e6ad6ac"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/74978c73-22ed-4fd5-9de2-85878197ac55/resourceGroups/AzureSynapseSushRG/providers/Microsoft.Synapse/workspaces/azuresynapsesushworkspace/bigDataPools/sparkpool1",
						"name": "sparkpool1",
						"type": "Spark",
						"endpoint": "https://azuresynapsesushworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from notebookutils import mssparkutils\n",
							"mssparkutils.notebook.help()\n",
							""
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"source": [
							"from notebookutils import mssparkutils\n",
							"firstName = 'Maheer'\n",
							"mssparkutils.notebook.exit(firstName)\n",
							""
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"source": [
							"lastname = 'Shaik'\n",
							"print(lastname)"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_MSSparkUtils_run')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "fdc804e3-dfa0-4b29-b69c-5b62b05bf581"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/74978c73-22ed-4fd5-9de2-85878197ac55/resourceGroups/AzureSynapseSushRG/providers/Microsoft.Synapse/workspaces/azuresynapsesushworkspace/bigDataPools/sparkpool1",
						"name": "sparkpool1",
						"type": "Spark",
						"endpoint": "https://azuresynapsesushworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"tags": [
								"parameters"
							]
						},
						"source": [
							"firstName = 'Maheer'\n",
							"lastname = 'Shaik'\n",
							""
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"source": [
							"from notebookutils import mssparkutils\n",
							"\n",
							"mssparkutils.notebook.exit('Your full name is ' + firstName + ' ' + lastname)\n",
							""
						],
						"outputs": [],
						"execution_count": 4
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_ReadByPipeline')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "3f0f87b1-877b-4703-8375-0e21064f78ef"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"tags": [
								"parameters"
							]
						},
						"source": [
							"name = \"Hello Susmita\""
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"source": [
							"print(name)"
						],
						"outputs": [],
						"execution_count": 4
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_txtbtnUI')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "c0473baa-a93c-4859-9976-12e8376e4e6c"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from ipywidgets import widgets\n",
							"\n",
							"lbl1= widgets.Label(value='First Name')\n",
							"display(lbl1)\n",
							"txt1=widgets.Text()\n",
							"display(txt1)\n",
							"\n",
							"lbl2= widgets.Label(value='Second Name')\n",
							"display(lbl2)\n",
							"txt2=widgets.Text()\n",
							"display(txt2)\n",
							"\n",
							"btn= widgets.Button(description ='Get Full Name')\n",
							"display(btn)\n",
							"\n",
							"lblFullname= widgets.Label()\n",
							"display(lblFullname)\n",
							"\n",
							"def getfullname(b):\n",
							"    lblFullname.value = 'Full Name is : ' + txt1.value + ' ' + txt2.value \n",
							"\n",
							"btn.on_click(getfullname)"
						],
						"outputs": [],
						"execution_count": 4
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebookwritecsvparquet')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "a85be6ee-f9b1-4479-a453-7b45824a81a7"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							}
						},
						"source": [
							"%%pyspark\n",
							"df = spark.sql(\"select * from nyctaxi.PassengerCountStats\")\n",
							"df.write.mode(\"overwrite\").csv(\"/NYCTaxi/csvfile\")\n",
							"df.write.mode(\"overwrite\").parquet(\"/NYCTaxi/parquetfile\")"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sparkpool1')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 3,
					"minNodeCount": 3
				},
				"nodeCount": 10,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.4",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dedicatedsushsqlpool')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_MSSparkUtils_Env')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "c4d50377-458e-462e-9d38-c8b0b59a52db"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/74978c73-22ed-4fd5-9de2-85878197ac55/resourceGroups/AzureSynapseSushRG/providers/Microsoft.Synapse/workspaces/azuresynapsesushworkspace/bigDataPools/sparkpool1",
						"name": "sparkpool1",
						"type": "Spark",
						"endpoint": "https://azuresynapsesushworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"from notebookutils import mssparkutils\n",
							"mssparkutils.env.help()\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"mssparkutils.env.getUserName()\n",
							"mssparkutils.env.getUserId()\n",
							"mssparkutils.env.getJobId()\n",
							"mssparkutils.env.getWorkspaceName()\n",
							"mssparkutils.env.getPoolName()\n",
							"mssparkutils.env.getClusterId()"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_ReadADLFcsvFile')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "a2246490-cf9b-48e9-931f-3a5d5dc87ade"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/74978c73-22ed-4fd5-9de2-85878197ac55/resourceGroups/AzureSynapseSushRG/providers/Microsoft.Synapse/workspaces/azuresynapsesushworkspace/bigDataPools/sparkpool1",
						"name": "sparkpool1",
						"type": "Spark",
						"endpoint": "https://azuresynapsesushworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\n",
							"df = spark.read.load('abfss://azuresynapsesushcontainer@azuresynapsesushadlsgen2.dfs.core.windows.net/synapsedemo/Employees.csv', format='csv', header=True)\n",
							"display(df.limit(10))\n",
							""
						],
						"outputs": [],
						"execution_count": 2
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Pipeline_ReadADLSCsvFile')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Notebook1",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "Notebook_ReadADLFcsvFile",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool1",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {},
							"driverSize": "Small"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/Notebook_ReadADLFcsvFile')]",
				"[concat(variables('workspaceId'), '/bigDataPools/sparkpool1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_MSSparkUtils_runtime')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "a5338f68-3302-4cf2-8e05-d523202f579f"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/74978c73-22ed-4fd5-9de2-85878197ac55/resourceGroups/AzureSynapseSushRG/providers/Microsoft.Synapse/workspaces/azuresynapsesushworkspace/bigDataPools/sparkpool1",
						"name": "sparkpool1",
						"type": "Spark",
						"endpoint": "https://azuresynapsesushworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"from notebookutils import mssparkutils\n",
							"mssparkutils.runtime.context"
						],
						"outputs": [],
						"execution_count": 4
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Pipeline_MSSparkUtils_Runtime')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Notebook_MSSparkUtils_runtime",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "Notebook_MSSparkUtils_runtime",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool1",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {},
							"driverSize": "Small"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/Notebook_MSSparkUtils_runtime')]",
				"[concat(variables('workspaceId'), '/bigDataPools/sparkpool1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_MSSparkUtils_Credentials')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "0d3cc388-a480-4a76-aea3-e948c63367f4"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/74978c73-22ed-4fd5-9de2-85878197ac55/resourceGroups/AzureSynapseSushRG/providers/Microsoft.Synapse/workspaces/azuresynapsesushworkspace/bigDataPools/sparkpool1",
						"name": "sparkpool1",
						"type": "Spark",
						"endpoint": "https://azuresynapsesushworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"from notebookutils import mssparkutils\n",
							"mssparkutils.credentials.help()\n",
							""
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"mssparkutils.credentials.getSecret('KV-DEV-ADF-Sush','sc-storageaccountadfsush-connectionstring')"
						],
						"outputs": [],
						"execution_count": 11
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AzureDataLakeStorage_synapse')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('AzureDataLakeStorage_synapse_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('AzureDataLakeStorage_synapse_accountKey')]"
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook_mount_adls_linkedservice')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "16b14a6e-aa82-4758-a3dd-54d1665e59d2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/74978c73-22ed-4fd5-9de2-85878197ac55/resourceGroups/AzureSynapseSushRG/providers/Microsoft.Synapse/workspaces/azuresynapsesushworkspace/bigDataPools/sparkpool1",
						"name": "sparkpool1",
						"type": "Spark",
						"endpoint": "https://azuresynapsesushworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"from notebookutils import mssparkutils\n",
							"mssparkutils.fs.mount(\n",
							"'abfss://azuresynapsesushcontainer@azuresynapsesushadlsgen2.dfs.core.windows.net',\n",
							"'/test',\n",
							"{'linkedService':'AzureDataLakeStorage_synapse'}\n",
							"\n",
							")\n",
							""
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"jobId= mssparkutils.env.getJobId()\n",
							"display(jobId)\n",
							"df = spark.read.load(\"synfs:/\" + jobId + \"/test/synapsedemo/Employees.csv\", format='csv', header=True)\n",
							"df.show()"
						],
						"outputs": [],
						"execution_count": 12
					}
				]
			},
			"dependsOn": []
		}
	]
}